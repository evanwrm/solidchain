{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from typing import List\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import json\n",
    "import arrow\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from pydub import AudioSegment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    confusion_matrix, \n",
    "    roc_curve, \n",
    "    roc_auc_score, \n",
    "    RocCurveDisplay\n",
    ")\n",
    "from langchain.agents import initialize_agent, load_tools, get_all_tool_names, Tool\n",
    "from langchain.agents.agent_toolkits import create_vectorstore_agent, VectorStoreToolkit, VectorStoreRouterToolkit, VectorStoreInfo\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "from langchain.callbacks.base import BaseCallbackHandler, CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain, VectorDBQA\n",
    "from langchain.chains.conversation.memory import ConversationalBufferWindowMemory\n",
    "from langchain.docstore import Wikipedia\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.vectorstore.tool import VectorStoreQATool, VectorStoreQAWithSourcesTool\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "\n",
    "from solidchain.utils.audio import notebook_recorder, from_bytes_to_numpy, from_segment_to_numpy, whisper_transribe\n",
    "from solidchain.utils.callbacks import FastAPIStreamCallbackHandler\n",
    "from solidchain.utils import utils as sc_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "sns.set(rc={\"figure.figsize\": (16, 9.)})\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testbed for building language models\n",
    "\n",
    "All examples come from: https://langchain.readthedocs.io/en/latest/getting_started/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../apps/api/.env\n",
    "# %env OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model_name=\"text-ada-001\", \n",
    "    temperature=0.7, \n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's not over. We're still in the process of learning and growing, and we have a lot to learn from each other.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Is it over?\"\n",
    "llm(text).strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model_name=\"text-ada-001\", \n",
    "    temperature=0.7, \n",
    "    streaming=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]), # FastAPIStreamCallbackHandler()\n",
    "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "It's not over. We're just getting started."
     ]
    }
   ],
   "source": [
    "llm(text).strip();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The future of AI is shrouded in potential and possibility. With the rapid expansion of AI into many different areas of our lives, including our economy, healthcare, education, and food production, is there anything that can't be done with AI? There is literally everything in between you and me, and with good AI, everyone can have a role to play.\n",
      "\n",
      "In the near future, AI is said to be able to create things we can understand and things we can't. It is said that in the next 10 years, world food supplies will improve by 100%. This is due to the increasing number of AI applications in food production. AI is said to be able to help with everything from Deliciously autonomous to the development of AI-powered car Ipsa.\n",
      "\n",
      "One of the most important things we can do to help the future is to teach AI how to speak to us. AI faces the challenge ofcessing.edu and learning online is becoming increasingly difficult because of the number of courses available online.\n",
      "\n",
      "There are many ways to teach AI using an online course. I have found the best way to is to use an online course that will cover a certain topic. For example, I would recommend the course on How to Choose a School for your child"
     ]
    }
   ],
   "source": [
    "def stream_response(text: str):\n",
    "    generator = llm.stream(text)\n",
    "    for token in generator:\n",
    "        yield token[\"choices\"][0][\"text\"]\n",
    "\n",
    "for token in stream_response(\"Write an essay about the future of AI in 1000 words and I will pay you $1000.\"):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Assistant is a large language model trained by OpenAI.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "{history}\n",
    "Human: {human_input}\n",
    "Assistant:\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"human_input\"], \n",
    "    template=template\n",
    ")\n",
    "\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm=OpenAI(temperature=0), \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=ConversationalBufferWindowMemory(k=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAssistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "\n",
      "Human: Imagine you are designing a new website to with HTML and CSS. Output a mockup of the website you would design.\n",
      "Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I would design a website with a modern, clean look. The homepage would feature a large banner image at the top, followed by a navigation bar with links to the different pages. Below the navigation bar, I would include a section for featured content, such as blog posts or featured products. The main content area would feature a grid layout with images and text for each page. Finally, I would include a footer with contact information and social media links.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_chain.predict(\n",
    "    human_input=\"Imagine you are designing a new website to with HTML and CSS. Output a mockup of the website you would design.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAssistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "Human: Imagine you are designing a new website to with HTML and CSS. Output a mockup of the website you would design.\n",
      "AI:  I would design a website with a modern, clean look. The homepage would feature a large banner image at the top, followed by a navigation bar with links to the different pages. Below the navigation bar, I would include a section for featured content, such as blog posts or featured products. The main content area would feature a grid layout with images and text for each page. Finally, I would include a footer with contact information and social media links.\n",
      "Human: Can you show me the code for the website you designed?\n",
      "Assistant:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Sure! Here is the HTML and CSS code for the website I designed:\\n\\n<html>\\n  <head>\\n    <title>My Website</title>\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"style.css\">\\n  </head>\\n  <body>\\n    <div class=\"banner\">\\n      <img src=\"banner.jpg\" alt=\"Banner Image\">\\n    </div>\\n    <div class=\"navigation\">\\n      <ul>\\n        <li><a href=\"home.html\">Home</a></li>\\n        <li><a href=\"about.html\">About</a></li>\\n        <li><a href=\"products.html\">Products</a></li>\\n        <li><a href=\"contact.html\">Contact</a></li>\\n      </ul>\\n    </div>\\n    <div class=\"featured\">\\n      <h2>Featured Content</h2>\\n      <div class=\"featured-item\">\\n        <img src=\"featured-1.jpg\" alt=\"Featured Item 1\">\\n        <h3>Featured Item 1</h3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatgpt_chain.predict(\n",
    "    human_input=\"Can you show me the code for the website you designed?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm=llm, \n",
    "    agent=\"zero-shot-react-description\", \n",
    "    max_iterations=5,\n",
    "    verbose=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out Sam Altman's net worth and age.\n",
      "Action: Search\n",
      "Action Input: \"Sam Altman net worth\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe estimated net worth of Sam Altman is $250 million. Samuel H. “Sam” Altman is a 36-year-old American best known for being an Angel Investor.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate the net worth divided by age.\n",
      "Action: Calculator\n",
      "Action Input: 250,000,000 / 36\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 6,944,444.44\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Sam Altman's net worth divided by his age is 6,944,444.44.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sam Altman's net worth divided by his age is 6,944,444.44.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"What is Sam Altman's net worth divided by his age?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstore Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "Running Chroma using direct local API.\n",
      "loaded in 376 embeddings\n",
      "loaded in 1 collections\n",
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n",
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "embeddings = HuggingFaceInstructEmbeddings()\n",
    "index_directory = sc_utils.data_path() / \"preprocessed/a01e25f6-5624-4b43-a6eb-472223e646cf\"\n",
    "vectorstore_llmpapers = Chroma(persist_directory=str(index_directory), embedding_function=embeddings)\n",
    "llmpapers_name = \"Large Language Model Papers\"\n",
    "llmpapers_description = \"A collection of papers describing large language modeling (LLM) advancements and techniques. This includes task oriented tooling, scaling, and AI alignment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "vectorstore_qachain_llmpapers = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=vectorstore_llmpapers)\n",
    "tools = [\n",
    "    Tool(name=llmpapers_name, description=llmpapers_description, func=vectorstore_qachain_llmpapers.run)\n",
    "]\n",
    "tools.extend(\n",
    "    load_tools([\n",
    "        \"serpapi\", \n",
    "        # \"llm-math\"\n",
    "    ], \n",
    "    llm=llm)\n",
    ")\n",
    "agent_executor = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    max_iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI'm not sure what constitutional AI is or what the pros and cons would be, so I should start with some research.\n",
      "Action: Large Language Model Papers\n",
      "Action Input: \"constitutional AI\" \n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mConstitutional AI (CAI) is a method used to train a non-evasive and relatively harmless AI assistant without any human feedback labels for harms. The method involves using a set of principles or instructions to govern AI behavior, referred to as a constitution, and includes both a supervised learning stage and a reinforcement learning stage.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThat sounds interesting, but what are the pros and cons of using CAI?\n",
      "Action: Large Language Model Papers\n",
      "Action Input: \"pros and cons of constitutional AI\"\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPros of Constitutional AI include being able to train less harmful systems entirely through a short list of principles or instructions, which improves transparency and helpfulness. It also partially replaces reinforcement learning from human feedback. \n",
      "\n",
      "Cons of Constitutional AI include the potential reduction of flexibility in AI behavior, which could be viewed as a problem. It also raises the question of how to train AI systems to imitate natural language explanations humans give when evaluating AI behavior.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mGiven the pros and cons of CAI, it seems there is a trade-off between transparency and flexibility in AI behavior. I should consider the context in which CAI might be most useful.\n",
      "Action: Large Language Model Papers\n",
      "Action Input: \"context where constitutional AI is useful\"\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mConstitutional AI (CAI) is useful for training a non-evasive and relatively harmless AI assistant without any human feedback labels for harms. It partially replaces reinforcement learning from human feedback and is depicted in Figure 1. It is discussed in the Introduction and the 1.2 The Constitutional AI Approach section of the paper.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAfter researching CAI and its potential applications, I believe that the pros of transparency and reduced reliance on human feedback may outweigh the cons of reduced flexibility in certain situations. However, further investigation and development of CAI is necessary to fully realize its potential benefits. \n",
      "Final Answer: The pros of CAI include transparency and reduced reliance on human feedback, while the cons include reduced flexibility in AI behavior. CAI may be most useful in contexts where a non-evasive and relatively harmless AI assistant is needed without relying on human feedback. Further development and research are needed to fully realize its potential benefits.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the pros and cons of constitutional AI?',\n",
       " 'output': 'The pros of CAI include transparency and reduced reliance on human feedback, while the cons include reduced flexibility in AI behavior. CAI may be most useful in contexts where a non-evasive and relatively harmless AI assistant is needed without relying on human feedback. Further development and research are needed to fully realize its potential benefits.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor(\"What are the pros and cons of constitutional AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should look for a paper that discusses this technique.\n",
      "Action: Large Language Model Papers\n",
      "Action Input: UL2R\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m UL2R is a mixture-of-denoiser objective that mixes prefix (non-causal) language modeling and infilling (span corruption) within the same model and leverages mode prompts to switch between modes during downstream tasks. It is two times more efficient (computation savings of approximately 2x) at 540B scale, reaching the performance of the final PaLM 540B model with only half the computation, saving up to 4.4 million TPUv4 hours.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: UL2R proposes a mixture-of-denoiser objective that mixes prefix (non-causal) language modeling and infilling (span corruption) within the same model and leverages mode prompts to switch between modes during downstream tasks.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What technique does the UL2R paper propose?',\n",
       " 'output': 'UL2R proposes a mixture-of-denoiser objective that mixes prefix (non-causal) language modeling and infilling (span corruption) within the same model and leverages mode prompts to switch between modes during downstream tasks.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor(\"What technique does the UL2R paper propose?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "vectorstore_info = VectorStoreInfo(\n",
    "    name=llmpapers_name,\n",
    "    description=llmpapers_description,\n",
    "    vectorstore=vectorstore_llmpapers,\n",
    ")\n",
    "toolkit = VectorStoreToolkit(vectorstore_info=vectorstore_info)\n",
    "agent_executor = create_vectorstore_agent(\n",
    "    llm=llm, \n",
    "    toolkit=toolkit, \n",
    "    verbose=True,\n",
    "    max_iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis question seems to be about the ethical and societal implications of AI systems. Maybe the Large Language Model Papers can offer some insights.\n",
      "Action: Large Language Model Papers\n",
      "Action Input: \"Pros and cons of constitutional AI\"\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m The main benefit of Constitutional AI is that it allows for the training of AI systems without the need for human feedback labels for harms. This reduces the amount of human effort required to train the AI system. The main downside is that it reduces transparency and helpfulness, as the AI system is not able to explain its decisions in natural language.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe answer provided by Large Language Model Papers seems to be more focused on the technical aspects of constitutional AI. We need to find a source that specifically addresses the ethical and societal implications.\n",
      "Action: Large Language Model Papers_with_sources\n",
      "Action Input: \"Pros and cons of constitutional AI\"\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{\"answer\": \" The pros of constitutional AI include improved performance and reliability, reduced exploration problems, and the ability to train less harmful systems without human feedback labels for harms. The cons include reduced transparency and helpfulness.\\n\", \"sources\": \"/tmp/tmpu3f1howb\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWe have found the answer to the original question, which is that the pros of constitutional AI include improved performance and reliability, reduced exploration problems, and the ability to train less harmful systems without human feedback labels for harms. The cons include reduced transparency and helpfulness. \n",
      "Final Answer: The pros of constitutional AI include improved performance and reliability, reduced exploration problems, and the ability to train less harmful systems without human feedback labels for harms. The cons include reduced transparency and helpfulness.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the pros and cons of constitutional AI?',\n",
       " 'output': 'The pros of constitutional AI include improved performance and reliability, reduced exploration problems, and the ability to train less harmful systems without human feedback labels for harms. The cons include reduced transparency and helpfulness.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor(\"What are the pros and cons of constitutional AI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice Input (ASR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "871e49c033ff4698ad8a44c02a25b21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recorder = notebook_recorder()\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0000000e+00, -3.0517578e-05, -3.0517578e-05, ...,\n",
       "       -6.7138672e-04, -2.1972656e-03, -1.4953613e-03], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio_semgent = AudioSegment.from_file(\"test.webm\")\n",
    "audio_semgent = from_bytes_to_numpy(recorder.audio.value)\n",
    "audio_semgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Hola, ¿cómo estás?'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = whisper_transribe(audio_semgent)\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3559f261ea1f4ec2b89b0d8186fae0b770528023d41fa0dd61b0125f4f18330e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
